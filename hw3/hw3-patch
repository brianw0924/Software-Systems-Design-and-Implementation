diff --git a/include/uapi/asm-generic/unistd.h b/include/uapi/asm-generic/unistd.h
index 1fc8faa6e973..4e7def488676 100644
--- a/include/uapi/asm-generic/unistd.h
+++ b/include/uapi/asm-generic/unistd.h
@@ -850,9 +850,11 @@ __SYSCALL(__NR_pidfd_open, sys_pidfd_open)
 #define __NR_clone3 435
 __SYSCALL(__NR_clone3, sys_clone3)
 #endif
+#define __NR_expose_pte 436
+__SYSCALL(__NR_expose_pte, sys_expose_pte)
 
 #undef __NR_syscalls
-#define __NR_syscalls 436
+#define __NR_syscalls 437
 
 /*
  * 32 bit systems traditionally used different
diff --git a/kernel/sys.c b/kernel/sys.c
index a611d1d58c7d..44a83b05d5a9 100644
--- a/kernel/sys.c
+++ b/kernel/sys.c
@@ -4,7 +4,7 @@
  *
  *  Copyright (C) 1991, 1992  Linus Torvalds
  */
-
+#include <linux/expose_pte.h>
 #include <linux/export.h>
 #include <linux/mm.h>
 #include <linux/utsname.h>
@@ -2581,6 +2581,73 @@ SYSCALL_DEFINE1(sysinfo, struct sysinfo __user *, info)
 	if (copy_to_user(info, &val, sizeof(struct sysinfo)))
 		return -EFAULT;
 
+	return 0;
+}
+
+SYSCALL_DEFINE1(expose_pte, struct expose_pte_args __user *, args)
+{
+
+	// int remap_pfn_range (
+	//	struct vm_area_struct * vma, (vma of the target addr)
+	// 	unsigned long addr, (target user addr)
+	// 	unsigned long pfn, (the physical addr from kernel memory)
+	// 	unsigned long size, (size you want to map, should align page size)
+	// 	pgprot_t prot
+	// );
+	pgd_t *pgd;
+	pud_t *pud;
+	pmd_t *pmd;
+	pte_t *pte;
+	int ret;
+	unsigned long i = 0,
+		pte_count = 1 + ((args->end_vaddr >> PMD_SHIFT) - (args->begin_vaddr >> PMD_SHIFT));
+	struct task_struct *sheep_task = get_pid_task(find_get_pid(args->pid), PIDTYPE_PID);
+	struct task_struct *test_task = get_pid_task(find_get_pid(current->pid), PIDTYPE_PID);
+	struct mm_struct *sheep_mm = get_task_mm(sheep_task);
+	struct mm_struct *test_mm = get_task_mm(test_task);
+	struct vm_area_struct *test_vma;
+	unsigned long next_vaddr = args->begin_vaddr, pte_paddr;
+
+	// remap target PTE to remapped_pte
+
+	down_read(&sheep_mm->mmap_sem);
+	pr_info("#####################\n");
+	for(; i < pte_count; i++, next_vaddr+= (1 << PMD_SHIFT)) {
+		pr_info("next_vaddr: %lx\n", next_vaddr);
+		test_vma = find_vma(test_mm, args->begin_pte_vaddr + i * PAGE_SIZE);
+
+		// walk through page table, find the pte physical addr
+		pgd = pgd_offset(sheep_mm, next_vaddr);
+		pud = pud_offset(pgd, next_vaddr);
+		pmd = pmd_offset(pud, next_vaddr);
+		pte = pte_offset_map(pmd, next_vaddr);
+		pte_paddr = pmd_page_paddr(READ_ONCE(*(pmd)));
+		pr_info("PTE pa: %llx\n", pmd_page_paddr(READ_ONCE(*(pmd))));
+		pr_info("pa: %llx\n", pte_val(*pte));
+		if(pte_paddr) {
+			// remap PTE
+			ret = remap_pfn_range(
+				test_vma,
+				(args->begin_pte_vaddr + i * PAGE_SIZE),
+				pmd_page_paddr(READ_ONCE(*(pmd))),
+				PAGE_SIZE,
+				test_vma->vm_page_prot
+				);
+			
+			// fill in flattened table entry
+			*((unsigned long*)(args->begin_fpt_vaddr + i * 8)) = args->begin_pte_vaddr + i * PAGE_SIZE;
+		} else {
+			*((unsigned long*)(args->begin_fpt_vaddr + i * 8)) = 0;
+		}
+	}
+	pr_info("#####################\n");
+	up_read(&sheep_mm->mmap_sem);
+
+	
+	
+
+
+
 	return 0;
 }
 
